{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1,779,127 articles from 519 files.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import os, json, pandas as pd\n",
    "import re, numpy as np,\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import seaborn as sns, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2037bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/aniqakhan/Desktop/Dissertation/NELA-GT2020/nela-gt-2020/newsdata'\n",
    "\n",
    "all_articles = []\n",
    "bad_files = []\n",
    "\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if not file.endswith('.json'):\n",
    "            continue\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                js = json.load(f)\n",
    "                # Some dumps are list-of-articles; others may be dicts\n",
    "                if isinstance(js, list):\n",
    "                    for a in js:\n",
    "                        a['_source_file'] = file\n",
    "                        all_articles.append(a)\n",
    "                elif isinstance(js, dict):\n",
    "                    arts = js.get('articles') or js.get('data') or []\n",
    "                    for a in arts:\n",
    "                        a['_source_file'] = file\n",
    "                        all_articles.append(a)\n",
    "        except Exception as e:\n",
    "            bad_files.append((file, str(e)))\n",
    "\n",
    "df = pd.DataFrame(all_articles)\n",
    "print(f\"Loaded {len(df):,} articles from {len(all_articles)>0 and len(set([a['_source_file'] for a in all_articles]))} files.\")\n",
    "if bad_files:\n",
    "    print(\"Skipped files:\", bad_files[:5], \"…\")\n",
    "\n",
    "labels_df = pd.read_csv('/Users/aniqakhan/Desktop/Dissertation/NELA-GT2020/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env1/lib/python3.9/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Introducing the huggingface MBFC dataset \n",
    "mbfc_df = pd.read_csv(\"hf://datasets/sergioburdisso/news_media_bias_and_factuality/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147be768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env1/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Loading all the dataframes\n",
    "_nela_df  = globals().get('nela_df',  globals().get('df'))\n",
    "_labels   = globals().get('labels_df', globals().get('labels'))\n",
    "_mbfc_df  = globals().get('mbfc_df',  globals().get('df_mbfc'))\n",
    "\n",
    "assert _nela_df is not None,  \"NELA articles df not found (expected nela_df or df).\"\n",
    "assert _labels is not None,   \"NELA labels df not found (expected labels_df or labels).\"\n",
    "assert _mbfc_df is not None,  \"MBFC HF df not found (expected mbfc_df or df_mbfc).\"\n",
    "\n",
    "nela = _nela_df.copy()\n",
    "labels_df = _labels.copy()\n",
    "mbfc = _mbfc_df.copy()\n",
    "\n",
    "if 'source' not in nela.columns: # Ensuring NELA has 'source'\n",
    "    for alt in ['domain', 'site', 'outlet', 'publisher']:\n",
    "        if alt in nela.columns:\n",
    "            nela = nela.rename(columns={alt: 'source'})\n",
    "            break\n",
    "assert 'source' in nela.columns, \"No 'source' column in NELA articles.\"\n",
    "\n",
    "# Ensure labels_df has ('source','label') where label is numeric 0/1/2\n",
    "if 'label' not in labels_df.columns:\n",
    "    for alt in ['bias', 'mbfc_bias', 'nela_label']:\n",
    "        if alt in labels_df.columns:\n",
    "            labels_df = labels_df.rename(columns={alt: 'label'})\n",
    "            break\n",
    "assert 'label' in labels_df.columns and 'source' in labels_df.columns, \\\n",
    "    \"labels_df must include 'source' and 'label' (0/1/2).\"\n",
    "\n",
    "if 'source' not in mbfc.columns: # Doing same for MBFC\n",
    "    for alt in ['domain', 'site', 'news_source']:\n",
    "        if alt in mbfc.columns:\n",
    "            mbfc = mbfc.rename(columns={alt: 'source'})\n",
    "            break\n",
    "assert 'source' in mbfc.columns, \"MBFC df must include a 'source' column.\"\n",
    "\n",
    "bias_col_detect = None\n",
    "for c in ['bias_label','bias','label','mbfc_bias']:\n",
    "    if c in mbfc.columns:\n",
    "        bias_col_detect = c\n",
    "        break\n",
    "assert bias_col_detect is not None, \"Could not find a bias label column in MBFC df.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After NELA-labels merge — labeled: 1290431 | unlabeled: 490364\n"
     ]
    }
   ],
   "source": [
    "#Cleaning part\n",
    "MULTIPART_TLDS = {\n",
    "    \"co.uk\",\"ac.uk\",\"gov.uk\",\"nhs.uk\",\"sch.uk\",\"ltd.uk\",\"plc.uk\",\n",
    "    \"com.au\",\"net.au\",\"org.au\",\"edu.au\",\"gov.au\",\n",
    "    \"co.nz\",\"org.nz\",\"govt.nz\",\n",
    "    \"co.in\",\"org.in\",\"net.in\",\"ac.in\",\"gov.in\",\n",
    "    \"co.jp\",\"co.kr\",\"com.sg\",\"com.my\",\"com.br\",\"com.tr\"\n",
    "}\n",
    "\n",
    "def clean_source(raw):\n",
    "    if pd.isna(raw):\n",
    "        return np.nan\n",
    "    s = str(raw).strip().lower()\n",
    "    s = re.sub(r'^https?://', '', s)\n",
    "    s = re.sub(r'^www\\.', '', s)\n",
    "    s = s.split('/')[0]  # drop path/query\n",
    "    # handle multi-part TLDs first\n",
    "    for tld in MULTIPART_TLDS:\n",
    "        if s.endswith('.' + tld):\n",
    "            s = s[:-(len(tld) + 1)]\n",
    "            break\n",
    "    else:\n",
    "        # single-part TLD\n",
    "        s = re.sub(r'\\.[a-z]{2,}$', '', s)\n",
    "    return s\n",
    "\n",
    "nela['source_clean']      = nela['source'].apply(clean_source)\n",
    "labels_df['source_clean'] = labels_df['source'].apply(clean_source)\n",
    "mbfc['source_clean']      = mbfc['source'].apply(clean_source)\n",
    "\n",
    "#Merging the datasets together\n",
    "merged = nela.merge(labels_df[['source_clean','label']], on='source_clean', how='left', suffixes=('','_nela'))\n",
    "print(\"After NELA-labels merge — labeled:\", merged['label'].notna().sum(),\n",
    "      \"| unlabeled:\", merged['label'].isna().sum())\n",
    "\n",
    "mbfc_bias = mbfc[['source_clean', bias_col_detect]].rename(columns={bias_col_detect: 'mbfc_bias_text'})\n",
    "mbfc_bias['mbfc_bias_text'] = mbfc_bias['mbfc_bias_text'].astype(str).str.strip().str.upper()\n",
    "\n",
    "merged = merged.merge(mbfc_bias, on='source_clean', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ecc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy-labeled sources: 121\n",
      "Merge hit-rate (any label present): 96.68%\n",
      "\n",
      "Class balance BEFORE dropna():\n",
      "LEFT      766319\n",
      "RIGHT     672084\n",
      "CENTRE    340917\n",
      "NaN        61083\n",
      "Name: polarisation_class, dtype: int64\n",
      "\n",
      "Class balance (final):\n",
      "LEFT      766319\n",
      "RIGHT     672084\n",
      "CENTRE    340917\n",
      "Name: polarisation_class, dtype: int64\n",
      "Labeled rows kept: 1,779,320 / 1,840,403\n"
     ]
    }
   ],
   "source": [
    "#Doing a fuzzy match to try and match as many headlines as possible\n",
    "try:\n",
    "    from rapidfuzz import process, fuzz\n",
    "    need_fuzzy = merged['label'].isna() & merged['mbfc_bias_text'].isna()\n",
    "    unmatched = merged.loc[need_fuzzy, 'source_clean'].dropna().unique()\n",
    "\n",
    "    mbfc_sources = mbfc['source_clean'].dropna().unique()\n",
    "    mbfc_lookup  = dict(zip(mbfc['source_clean'], mbfc_bias.set_index('source_clean')['mbfc_bias_text']))\n",
    "\n",
    "    fuzzy_map = {}\n",
    "    for src in unmatched:\n",
    "        match = process.extractOne(src, mbfc_sources, scorer=fuzz.partial_ratio)\n",
    "        if match:\n",
    "            cand, score, _ = match\n",
    "            if score >= 90:\n",
    "                fuzzy_map[src] = mbfc_lookup.get(cand)\n",
    "\n",
    "    merged['mbfc_bias_text_fuzzy'] = merged['source_clean'].map(fuzzy_map)\n",
    "    print(\"Fuzzy-labeled sources:\", len(fuzzy_map))\n",
    "except Exception as e:\n",
    "    print(\"[Note] Skipping fuzzy match (rapidfuzz not available or error:\", e, \")\")\n",
    "    merged['mbfc_bias_text_fuzzy'] = np.nan\n",
    "\n",
    "#Merge hit-rate check \n",
    "merge_hit = merged['label'].notna() | merged['mbfc_bias_text'].notna() | merged['mbfc_bias_text_fuzzy'].notna()\n",
    "print(f\"Merge hit-rate (any label present): {merge_hit.mean():.2%}\")\n",
    "\n",
    "#Building the labels\n",
    "nela_num_to_3cat = {\n",
    "    0: 'LEFT', 1: 'CENTRE', 2: 'RIGHT',\n",
    "    0.0: 'LEFT', 1.0: 'CENTRE', 2.0: 'RIGHT',\n",
    "    '0': 'LEFT','1': 'CENTRE','2': 'RIGHT',\n",
    "    '0.0':'LEFT','1.0':'CENTRE','2.0':'RIGHT'\n",
    "}\n",
    "\n",
    "CENTRE_BUCKETS = {\n",
    "    'CENTER','CENTRE','LEAST_BIASED','LEAST-BIASED','LEAST BIASED',\n",
    "    'PRO_SCIENCE','PRO-SCIENCE','PRO SCIENCE','NEUTRAL','FACTUAL'\n",
    "}\n",
    "LEFT_BUCKETS  = {'LEFT','LEFT-CENTER','LEFT_CENTER','LEFT CENTER'}\n",
    "RIGHT_BUCKETS = {'RIGHT','RIGHT-CENTER','RIGHT_CENTER','RIGHT CENTER'}\n",
    "\n",
    "def map_mbfc_text_to_3cat(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    s = str(s).strip().upper()\n",
    "    if s in LEFT_BUCKETS:   return 'LEFT'\n",
    "    if s in RIGHT_BUCKETS:  return 'RIGHT'\n",
    "    if s in CENTRE_BUCKETS: return 'CENTRE'\n",
    "    # Drop questionable/satire/conspiracy/unknown/etc.\n",
    "    return np.nan\n",
    "\n",
    "def choose_label(row):\n",
    "    # 1) NELA numeric first\n",
    "    lab = row['label']\n",
    "    if pd.notna(lab):\n",
    "        mapped = nela_num_to_3cat.get(lab, nela_num_to_3cat.get(str(lab)))\n",
    "        if mapped is not None:\n",
    "            return mapped\n",
    "    # 2) MBFC exact\n",
    "    mapped = map_mbfc_text_to_3cat(row.get('mbfc_bias_text'))\n",
    "    if pd.notna(mapped):\n",
    "        return mapped\n",
    "    # 3) MBFC fuzzy\n",
    "    mapped = map_mbfc_text_to_3cat(row.get('mbfc_bias_text_fuzzy'))\n",
    "    if pd.notna(mapped):\n",
    "        return mapped\n",
    "    return np.nan\n",
    "\n",
    "merged['polarisation_class'] = merged.apply(choose_label, axis=1)\n",
    "\n",
    "print(\"\\nClass balance BEFORE dropna():\")\n",
    "print(merged['polarisation_class'].value_counts(dropna=False))\n",
    "\n",
    "#Keep only labeled rows\n",
    "labeled_df = merged.dropna(subset=['polarisation_class']).copy()\n",
    "labeled_df.reset_index(drop=True, inplace=True)\n",
    "print(\"\\nClass balance (final):\")\n",
    "print(labeled_df['polarisation_class'].value_counts())\n",
    "print(f\"Labeled rows kept: {len(labeled_df):,} / {len(merged):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb4f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with usable (≥40 chars) text: 1772948\n"
     ]
    }
   ],
   "source": [
    "#Text columns\n",
    "text_cols  = [c for c in ['content','text','article_text','body'] if c in labeled_df.columns]\n",
    "title_cols = [c for c in ['title','headline'] if c in labeled_df.columns]\n",
    "\n",
    "if text_cols:\n",
    "    labeled_df['__text__'] = labeled_df[text_cols[0]].astype(str)\n",
    "else:\n",
    "    if title_cols:\n",
    "        labeled_df['__text__'] = labeled_df[title_cols[0]].astype(str)\n",
    "    else:\n",
    "        raise ValueError(\"No text columns found (looked for content/text/article_text/body/title/headline).\")\n",
    "\n",
    "if text_cols and title_cols:\n",
    "    labeled_df['__text__'] = (labeled_df[title_cols[0]].astype(str) + \" \" + labeled_df[text_cols[0]].astype(str))\n",
    "\n",
    "labeled_df['__text__'] = labeled_df['__text__'].fillna(\"\").str.strip()\n",
    "\n",
    "#filtering for speed\n",
    "MIN_CHARS = 40    # set to None to disable\n",
    "SAMPLE_N  = None  # e.g., 200_000 to cap size\n",
    "\n",
    "if MIN_CHARS is not None:\n",
    "    labeled_df = labeled_df[labeled_df['__text__'].str.len() >= MIN_CHARS].copy()\n",
    "    print(\"Rows with usable (≥{} chars) text: {}\".format(MIN_CHARS, len(labeled_df)))\n",
    "else:\n",
    "    print(\"Rows with usable text:\", len(labeled_df))\n",
    "\n",
    "if SAMPLE_N is not None and len(labeled_df) > SAMPLE_N:\n",
    "    labeled_df = shuffle(labeled_df, random_state=42).iloc[:SAMPLE_N].copy()\n",
    "    print(f\"Sampled to {SAMPLE_N:,} rows for speed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466864f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeled_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_GROUP_SPLIT:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupShuffleSplit\n\u001b[0;32m----> 6\u001b[0m     groups \u001b[38;5;241m=\u001b[39m \u001b[43mlabeled_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_clean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown_source\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     gss \u001b[38;5;241m=\u001b[39m GroupShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      8\u001b[0m     train_idx, test_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(gss\u001b[38;5;241m.\u001b[39msplit(labeled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__text__\u001b[39m\u001b[38;5;124m'\u001b[39m], labeled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolarisation_class\u001b[39m\u001b[38;5;124m'\u001b[39m], groups\u001b[38;5;241m=\u001b[39mgroups))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labeled_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Train/test\n",
    "USE_GROUP_SPLIT = True\n",
    "\n",
    "if USE_GROUP_SPLIT:\n",
    "    from sklearn.model_selection import GroupShuffleSplit\n",
    "    groups = labeled_df['source_clean'].fillna('unknown_source')\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, test_idx = next(gss.split(labeled_df['__text__'], labeled_df['polarisation_class'], groups=groups))\n",
    "    X_train = labeled_df.iloc[train_idx]['__text__']\n",
    "    y_train = labeled_df.iloc[train_idx]['polarisation_class']\n",
    "    X_test  = labeled_df.iloc[test_idx]['__text__']\n",
    "    y_test  = labeled_df.iloc[test_idx]['polarisation_class']\n",
    "    print(f\"Grouped split by source → train sources: {groups.iloc[train_idx].nunique()}, test sources: {groups.iloc[test_idx].nunique()}\")\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        labeled_df['__text__'], labeled_df['polarisation_class'],\n",
    "        test_size=0.2, random_state=42, stratify=labeled_df['polarisation_class']\n",
    "    )\n",
    "\n",
    "#SVM pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        max_features=200_000,\n",
    "        ngram_range=(1,2),\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        sublinear_tf=True,\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\"\n",
    "    )),\n",
    "    (\"clf\", LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"\\nAccuracy: {acc:.3f} | Macro-F1: {macro_f1:.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix [LEFT, CENTRE, RIGHT]:\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=['LEFT','CENTRE','RIGHT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3895d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLEFT\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCENTRE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIGHT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m cm_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(\n\u001b[0;32m----> 5\u001b[0m     pd\u001b[38;5;241m.\u001b[39mCategorical(\u001b[43my_test\u001b[49m, categories\u001b[38;5;241m=\u001b[39mlabels),\n\u001b[1;32m      6\u001b[0m     pd\u001b[38;5;241m.\u001b[39mCategorical(y_pred, categories\u001b[38;5;241m=\u001b[39mlabels),\n\u001b[1;32m      7\u001b[0m     dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     11\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm_df, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m             xticklabels\u001b[38;5;241m=\u001b[39mlabels, yticklabels\u001b[38;5;241m=\u001b[39mlabels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "labels = ['LEFT','CENTRE','RIGHT']\n",
    "cm_df = pd.crosstab(\n",
    "    pd.Categorical(y_test, categories=labels),\n",
    "    pd.Categorical(y_pred, categories=labels),\n",
    "    dropna=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix — counts')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Row-normalized (recall view)\n",
    "cm_norm = cm_df.div(cm_df.sum(axis=1).replace(0,1), axis=0)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels, vmin=0, vmax=1)\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix — row-normalized')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing pipeline found; saved a default TF-IDF + LogisticRegression spec.\n",
      "Saved: ['nela_pipeline.joblib', 'nela_train_labels_3.csv', 'nela_train_text.csv']\n"
     ]
    }
   ],
   "source": [
    "#Code for meta model\n",
    "ROOT = Path.home() / \"Desktop\" / \"Dissertation\"\n",
    "ARTN = ROOT / \"nela_artifacts\"\n",
    "ARTN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# texts \n",
    "nela_texts  = labeled_df['__text__'].astype(str).fillna(\"\")\n",
    "\n",
    "# labels \n",
    "nela_labels = labeled_df['polarisation_class'].astype(str).str.upper().str.replace(\"CENTER\",\"CENTRE\", regex=False)\n",
    "\n",
    "# Normalise labels to LEFT / CENTRE / RIGHT\n",
    "y = pd.Series(nela_labels)\n",
    "if y.dtype.kind in \"iuf\":  # numeric codes 0/1/2 -> map\n",
    "    y = y.map({0:'LEFT', 1:'CENTRE', 2:'RIGHT'})\n",
    "y = (y.astype(str)\n",
    "       .str.upper()\n",
    "       .str.replace(\"CENTER\",\"CENTRE\", regex=False)\n",
    "       .str.strip())\n",
    "\n",
    "# Drop any unexpected labels\n",
    "mask = y.isin({'LEFT','CENTRE','RIGHT'})\n",
    "if (~mask).any():\n",
    "    print(\"Dropping rows with unexpected labels:\", y[~mask].value_counts().to_dict())\n",
    "    nela_texts = pd.Series(nela_texts)[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "# Save texts + labels\n",
    "pd.DataFrame({\"text\": nela_texts}).to_csv(ARTN / \"nela_train_text.csv\", index=False)\n",
    "y.to_csv(ARTN / \"nela_train_labels_3.csv\", index=False, header=[\"label\"])\n",
    "\n",
    "# Saving\n",
    "pipeline = None\n",
    "for name in (\"model_nela\", \"nela_pipeline\", \"pipe_nela\"):\n",
    "    try:\n",
    "        pipeline = eval(name)\n",
    "        print(f\"Using existing pipeline: {name}\")\n",
    "        break\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "\n",
    "if pipeline is None:\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words=\"english\")),\n",
    "        (\"clf\",   LogisticRegression(max_iter=1000, class_weight=\"balanced\", multi_class=\"auto\"))\n",
    "    ])\n",
    "    print(\"No existing pipeline found; saved a default TF-IDF + LogisticRegression spec.\")\n",
    "\n",
    "joblib.dump(pipeline, ARTN / \"nela_pipeline.joblib\")\n",
    "\n",
    "print(\"Saved:\", [p.name for p in ARTN.iterdir()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
